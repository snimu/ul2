{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from rich import print\n",
    "import einops\n",
    "import math\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianmuller/anaconda3/envs/attn/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "x = einops.repeat(torch.arange(20), \"length -> batch length\", batch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DENOISING_TOKEN = 100\n",
    "MASK_TOKEN = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">inputs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000e+02</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.8066e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.3438e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.0000e+00</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.0000e+00</span>,\n",
       "         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.0000e+00</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0000e+02</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.0537e-02</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.0000e+00</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.0000e+00</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.0000e+00</span>,\n",
       "         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.0000e+00</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.bfloat16<span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">targets</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1807</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7344</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1895</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9883</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1611</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3359</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0505</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1250</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5312</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2852</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2656</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1484</span><span style=\"font-weight: bold\">]]</span>,\n",
       "       <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.bfloat16<span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">x</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1807</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7344</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1895</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9883</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1611</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3359</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0505</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1250</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5312</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2852</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2656</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1484</span><span style=\"font-weight: bold\">]]</span>,\n",
       "       <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.bfloat16<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33minputs\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m1.0000e+02\u001b[0m,  \u001b[1;36m1.8066e-01\u001b[0m,  \u001b[1;36m7.3438e-01\u001b[0m, \u001b[1;36m-1.0000e+00\u001b[0m, \u001b[1;36m-1.0000e+00\u001b[0m,\n",
       "         \u001b[1;36m-1.0000e+00\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m1.0000e+02\u001b[0m,  \u001b[1;36m5.0537e-02\u001b[0m, \u001b[1;36m-1.0000e+00\u001b[0m, \u001b[1;36m-1.0000e+00\u001b[0m, \u001b[1;36m-1.0000e+00\u001b[0m,\n",
       "         \u001b[1;36m-1.0000e+00\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.bfloat16\u001b[1m)\u001b[0m\n",
       "\u001b[33mtargets\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.1807\u001b[0m, \u001b[1;36m0.7344\u001b[0m, \u001b[1;36m0.1895\u001b[0m, \u001b[1;36m0.9883\u001b[0m, \u001b[1;36m0.1611\u001b[0m, \u001b[1;36m0.3359\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.0505\u001b[0m, \u001b[1;36m0.1250\u001b[0m, \u001b[1;36m0.5312\u001b[0m, \u001b[1;36m0.2852\u001b[0m, \u001b[1;36m0.2656\u001b[0m, \u001b[1;36m0.1484\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.bfloat16\u001b[1m)\u001b[0m\n",
       "\u001b[33mx\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.1807\u001b[0m, \u001b[1;36m0.7344\u001b[0m, \u001b[1;36m0.1895\u001b[0m, \u001b[1;36m0.9883\u001b[0m, \u001b[1;36m0.1611\u001b[0m, \u001b[1;36m0.3359\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.0505\u001b[0m, \u001b[1;36m0.1250\u001b[0m, \u001b[1;36m0.5312\u001b[0m, \u001b[1;36m0.2852\u001b[0m, \u001b[1;36m0.2656\u001b[0m, \u001b[1;36m0.1484\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.bfloat16\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def mask_spans(\n",
    "    sequence: torch.Tensor,\n",
    "    mask_width: int,\n",
    "    num_masks: int,\n",
    "    max_percentage_masked: float,\n",
    "    causal: bool = False,\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    if causal:\n",
    "        targets = torch.zeros_like(sequence).copy_(sequence)\n",
    "    else:\n",
    "        targets = sequence.roll(1)\n",
    "        targets[:, 0] = DENOISING_TOKEN\n",
    "\n",
    "    num_masks = min(num_masks, math.floor(max_percentage_masked * sequence.shape[-1] / mask_width))\n",
    "\n",
    "    batch_size, seq_length = sequence.shape\n",
    "    mask = torch.randint(0, seq_length - mask_width + 1, (batch_size, num_masks))\n",
    "    \n",
    "    # Create a tensor to hold the mask\n",
    "    mask_tensor = torch.zeros_like(sequence)\n",
    "    \n",
    "    # Create a range for the mask width\n",
    "    width_range = torch.arange(mask_width).unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, mask_width)\n",
    "    \n",
    "    # Expand the mask to the desired width\n",
    "    mask_positions = mask.unsqueeze(-1) + width_range  # Shape: (batch_size, num_masks, mask_width)\n",
    "    \n",
    "    # Clip the positions to stay within sequence bounds\n",
    "    mask_positions = mask_positions.clamp(0, seq_length - 1)\n",
    "    \n",
    "    # Scatter the mask positions into the mask tensor\n",
    "    mask_tensor.scatter_(1, mask_positions.view(batch_size, -1), 1)\n",
    "\n",
    "    # Apply the mask to the sequence\n",
    "    inputs = sequence.masked_fill(mask_tensor.bool(), MASK_TOKEN)\n",
    "\n",
    "    # Add task token\n",
    "    inputs = inputs.roll(1, dims=-1)\n",
    "    inputs[:, 0] = DENOISING_TOKEN\n",
    "\n",
    "    return inputs, targets\n",
    "\n",
    "inputs, targets = mask_spans(x, 4, 2, 0.8, True)\n",
    "print(f\"{inputs=}\\n{targets=}\\n{x=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_s_denoised_data(\n",
    "        sequence: torch.Tensor,\n",
    "        mask_width: int | None,\n",
    "        masking_rate: float = 0.5,\n",
    "        causal: bool = False,\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    if causal:\n",
    "        targets = torch.zeros_like(sequence).copy_(sequence)  # copy sequence to not have negative downstream effects\n",
    "    else:\n",
    "        targets = sequence.roll(1)\n",
    "        targets[:, 0] = DENOISING_TOKEN\n",
    "\n",
    "    mask_width = mask_width or math.floor(masking_rate * sequence.shape[-1])\n",
    "    mask_width = min(mask_width, math.floor(masking_rate * sequence.shape[-1]))\n",
    "    inputs = sequence.roll(1, dims=-1)\n",
    "    inputs [:, -mask_width:] = MASK_TOKEN\n",
    "    inputs[:, 0] = DENOISING_TOKEN\n",
    "\n",
    "    return inputs, targets\n",
    "\n",
    "if False:\n",
    "    inputs, targets = get_s_denoised_data(x, None, 0.25, True)\n",
    "    print(f\"{inputs=}\\n{targets=}\\n{x=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_causal_data(sequence: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    targets  = sequence\n",
    "\n",
    "    # Inputs: add special token to beginning\n",
    "    # Just roll the tensor and replace the first (previously final) token to get the causality going\n",
    "    inputs = sequence.roll(1, dims=-1)\n",
    "    inputs[:, 0] = DENOISING_TOKEN\n",
    "\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m100\u001b[0m,   \u001b[1;36m0\u001b[0m,   \u001b[1;36m1\u001b[0m,   \u001b[1;36m2\u001b[0m,   \u001b[1;36m3\u001b[0m,   \u001b[1;36m4\u001b[0m,   \u001b[1;36m5\u001b[0m,   \u001b[1;36m6\u001b[0m,   \u001b[1;36m7\u001b[0m,   \u001b[1;36m8\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m9\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_get_causal_data():\n",
    "    sequence = einops.rearrange(torch.arange(10), \"s -> () s\")\n",
    "    print(sequence[:, :-1])\n",
    "    print(sequence[:, 1:])\n",
    "    inputs, targets = get_causal_data(sequence)\n",
    "    print(inputs)\n",
    "    print(targets)\n",
    "\n",
    "\n",
    "test_get_causal_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Create the base arrays for the learnable linear positional bias. This helps save some memory consumption & processing time\n",
    "    bias_range                    = torch.arange(-max_seq_len+1, 1).to(torch.bfloat16)\n",
    "    position_bias_base            = bias_range.unsqueeze(0) - bias_range.unsqueeze(1)\n",
    "    negative_infinity_matrix_base = torch.empty_like(position_bias_base).fill_(-float(\"inf\"))\n",
    "    causal_mask = torch.tril(torch.ones((max_seq_len, max_seq_len), dtype=torch.bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0000</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.0000</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.0000</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3262</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.0000</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.0000</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.0000</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1582</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5312</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.0000</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.0000</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7773</span><span style=\"font-weight: bold\">]]</span>,\n",
       "       <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.bfloat16<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m100.0000\u001b[0m,  \u001b[1;36m-1.0000\u001b[0m,  \u001b[1;36m-1.0000\u001b[0m,   \u001b[1;36m0.3262\u001b[0m,  \u001b[1;36m-1.0000\u001b[0m,  \u001b[1;36m-1.0000\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m100.0000\u001b[0m,   \u001b[1;36m0.1582\u001b[0m,   \u001b[1;36m0.5312\u001b[0m,  \u001b[1;36m-1.0000\u001b[0m,  \u001b[1;36m-1.0000\u001b[0m,   \u001b[1;36m0.7773\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.bfloat16\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., -inf, -inf, -inf, -inf, -inf<span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>., -inf,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., -inf,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., -inf, -inf<span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-8</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-8</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]]</span>,\n",
       "\n",
       "        <span style=\"font-weight: bold\">[[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., -inf, -inf, -inf, -inf, -inf<span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., -inf, -inf, -inf, -inf<span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., -inf, -inf, -inf<span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., -inf<span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>., -inf<span style=\"font-weight: bold\">]</span>,\n",
       "         <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-8</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-8</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.bfloat16<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m0\u001b[0m., -inf, -inf, -inf, -inf, -inf\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m4\u001b[0m., -inf,  \u001b[1;36m4\u001b[0m.,  \u001b[1;36m8\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-4\u001b[0m., \u001b[1;36m-4\u001b[0m.,  \u001b[1;36m0\u001b[0m., -inf,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m4\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-4\u001b[0m., \u001b[1;36m-4\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m., -inf, -inf\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-4\u001b[0m., \u001b[1;36m-4\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m4\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-8\u001b[0m., \u001b[1;36m-8\u001b[0m., \u001b[1;36m-4\u001b[0m., \u001b[1;36m-4\u001b[0m., \u001b[1;36m-4\u001b[0m.,  \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\n",
       "        \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m0\u001b[0m., -inf, -inf, -inf, -inf, -inf\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m., -inf, -inf, -inf, -inf\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-4\u001b[0m., \u001b[1;36m-4\u001b[0m.,  \u001b[1;36m0\u001b[0m., -inf, -inf, -inf\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-4\u001b[0m., \u001b[1;36m-4\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m., -inf\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-4\u001b[0m., \u001b[1;36m-4\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m., -inf\u001b[1m]\u001b[0m,\n",
       "         \u001b[1m[\u001b[0m\u001b[1;36m-8\u001b[0m., \u001b[1;36m-8\u001b[0m., \u001b[1;36m-4\u001b[0m., \u001b[1;36m-4\u001b[0m., \u001b[1;36m-4\u001b[0m.,  \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.bfloat16\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_mask(x: torch.Tensor) -> torch.Tensor:\n",
    "    masked_spans: torch.Tensor = (x == MASK_TOKEN).bool()\n",
    "    masked_spans = einops.repeat(masked_spans, 'b l -> b l h', h=x.shape[1])\n",
    "    masked_spans = masked_spans & masked_spans.swapaxes(1, 2)\n",
    "    masked_spans = masked_spans | causal_mask[:x.shape[1], :x.shape[1]].unsqueeze(0)\n",
    "    attn_mask = torch.where(masked_spans, position_bias_base[:x.shape[1], :x.shape[1]], negative_infinity_matrix_base[:x.shape[1], :x.shape[1]])\n",
    "    return attn_mask\n",
    "\n",
    "\n",
    "x = torch.rand(2, 6).to(dtype=torch.bfloat16)\n",
    "inputs, targets = mask_spans(x, 2, num_masks=100000000, max_percentage_masked=0.8, causal=True)\n",
    "attn_mask = make_mask(inputs)\n",
    "print(inputs)\n",
    "print(attn_mask)  # looks good\n",
    "# Can attention work with it?\n",
    "# q, k, v = torch.randn(2, 6, 8).to(dtype=torch.bfloat16), torch.randn(2, 6, 8).to(dtype=torch.bfloat16), torch.randn(2, 6, 8).to(dtype=torch.bfloat16)\n",
    "# print(attn_mask.shape, q.shape, k.shape, v.shape)\n",
    "# y = F.scaled_dot_product_attention(q, k, v, attn_mask)\n",
    "# print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
